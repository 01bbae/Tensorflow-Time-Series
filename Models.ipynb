{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78ef61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, losses, optimizers, Input, optimizers\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from time import sleep\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import pprint\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1bbbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a254d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(tf.config.list_physical_devices('GPU'))>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5661d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "print(device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dfd861",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_x_train = np.loadtxt(\"./data/X_x_train.txt\")\n",
    "X_y_train = np.loadtxt(\"./data/X_y_train.txt\")\n",
    "X_z_train = np.loadtxt(\"./data/X_z_train.txt\")\n",
    "y_train = np.loadtxt(\"./data/y_train.txt\")\n",
    "\n",
    "X_x_test = np.loadtxt(\"./data/X_x_train.txt\")\n",
    "X_y_test = np.loadtxt(\"./data/X_y_train.txt\")\n",
    "X_z_test = np.loadtxt(\"./data/X_z_train.txt\")\n",
    "y_test = np.loadtxt(\"./data/y_train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d025576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i, r in tqdm(X_x_train[:], total=X_x_train.shape[0], desc=\"printing graphs...\"):\n",
    "#     print(\"plot\" +str(i))\n",
    "#     row = X_x_train[i,:-1]\n",
    "#     y = X_x_train[i,-1:]\n",
    "#     print(label_names[int(y)-1])\n",
    "#     plt.plot(row)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ded89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_score_normalization(x):\n",
    "    x_m = np.mean(x, axis=1).reshape(-1,1)\n",
    "    x_std = np.std(x,axis=1).reshape(-1,1)\n",
    "    return (x-x_m)/x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6bc501",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f685c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_x_train_norm = norm.fit_transform(X_x_train)\n",
    "X_y_train_norm = norm.fit_transform(X_y_train)\n",
    "X_z_train_norm = norm.fit_transform(X_y_train)\n",
    "\n",
    "X_x_test_norm = norm.fit_transform(X_x_test)\n",
    "X_y_test_norm = norm.fit_transform(X_y_test)\n",
    "X_z_test_norm = norm.fit_transform(X_z_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd67c753",
   "metadata": {},
   "source": [
    "### Below I'm comparing two different concatenation functions.\n",
    "\n",
    "concat_xyz is vectorizing calculations while concat2_xyz is iterating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc18999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_xyz(x,y,z):\n",
    "    data = np.empty((x.shape[0],x.shape[1],3))\n",
    "#     x = np.expand_dims(x, axis=1) # same as x = x[:,np.newaxis,:]\n",
    "#     y = np.expand_dims(y, axis=1)\n",
    "#     z = np.expand_dims(z, axis=1)\n",
    "    data[:,:,0] = x\n",
    "    data[:,:,1] = y\n",
    "    data[:,:,2] = z\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5957825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#speed test purposes\n",
    "def concat2_xyz(x,y,z):\n",
    "    data = np.empty((x.shape[0],x.shape[1],3))\n",
    "    for i, rowx,rowy, rowz in zip(range(x.shape[0]),x,y,z):\n",
    "        data[i,:,0] = rowx.reshape(1,-1)\n",
    "        data[i,:,1] = rowy.reshape(1,-1)\n",
    "        data[i,:,2] = rowz.reshape(1,-1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911dfb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "X_xyz_norm_train =  concat_xyz(X_x_train_norm,X_y_train_norm, X_z_train_norm)\n",
    "X_xyz_norm_test = concat_xyz(X_x_test_norm,X_y_test_norm,X_z_test_norm)\n",
    "toc = time.perf_counter()\n",
    "print(f\"concat_xyz in {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f8b17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#speed test purposes\n",
    "tic = time.perf_counter()\n",
    "concat2_xyz(X_x_train_norm,X_y_train_norm, X_z_train_norm)\n",
    "concat_xyz(X_x_test_norm,X_y_test_norm,X_z_test_norm)\n",
    "toc = time.perf_counter()\n",
    "print(f\"concat2_xyz in {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b58b94",
   "metadata": {},
   "source": [
    "#### Vectorizing calculations is faster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aa19b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['Walking', 'Walking upstairs', 'Walking downstairs', 'Sitting', 'Standing', 'Laying']\n",
    "num_outputs = len(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adef527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "\n",
    "y_train = np.eye(len(label_names))[(y_train-1).astype(int)]\n",
    "y_test = np.eye(len(label_names))[(y_train-1).astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bcd1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_xyz_norm_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d23581",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_xyz_norm_train.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602c426b",
   "metadata": {},
   "source": [
    "In TF1 placeholder would be needed to get shape of `(None, 128, 3)` but here we take `(128, 3)` as input shape instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ebb536",
   "metadata": {},
   "source": [
    "<H1>Implementing CNN</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ec22ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.Sequential()\n",
    "cnn.add(layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=input_shape))\n",
    "# cnn.add(layers.MaxPool1D(pool_size=2))\n",
    "cnn.add(layers.Flatten())\n",
    "cnn.add(layers.Dense(100, activation='relu'))\n",
    "cnn.add(layers.Dense(30, activation='relu'))\n",
    "cnn.add(layers.Dense(num_outputs,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584f8db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f59b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "cnn.compile(optimizer=\"adam\",\n",
    "           loss=\"categorical_crossentropy\",\n",
    "           metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cfe256",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnhistory = cnn.fit(X_xyz_norm_train, y_train, epochs=100, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914130fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn.save(\"my_model\")\n",
    "# tensorflow_graph = tf.saved_model.load(\"my_model\")\n",
    "# x = np.random.uniform(size=(4, 32)).astype(np.float32)\n",
    "# predicted = tensorflow_graph(x).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1b2fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = cnnhistory.history['loss']\n",
    "epochs = range(1, len(loss_values)+1)\n",
    "\n",
    "plt.plot(epochs, loss_values, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec887f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_values = cnnhistory.history['accuracy']\n",
    "epochs = range(1, len(loss_values)+1)\n",
    "\n",
    "plt.plot(epochs, acc_values, label='Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43881807",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = cnn.predict(X_xyz_norm_test)\n",
    "pprint.pprint(y_test_pred)\n",
    "pprint.pprint(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc015f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.math.confusion_matrix(y_test,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840f505a",
   "metadata": {},
   "source": [
    "<H1>Implementing LSTM</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f633ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "\n",
    "lstm = models.Sequential()\n",
    "lstm.add(layers.Bidirectional(\n",
    "    layers.LSTM(128),input_shape=input_shape\n",
    "))\n",
    "\n",
    "lstm.add(layers.Dropout(rate=0.2))\n",
    "lstm.add(layers.Dense(6,activation=\"softmax\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466356da",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988ff08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.compile(optimizer = \"adam\",\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics = \"accuracy\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3de4a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmhistory = lstm.fit(X_xyz_norm_train,y_train,epochs = 100,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87735797",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = lstmhistory.history['loss']\n",
    "epochs = range(1, len(loss_values)+1)\n",
    "\n",
    "plt.plot(epochs, loss_values, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd69e1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_values = lstmhistory.history['accuracy']\n",
    "epochs = range(1, len(loss_values)+1)\n",
    "\n",
    "plt.plot(epochs, acc_values, label='Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad775d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.perf_counter()\n",
    "print(f\"notebook took {end - start:0.4f} seconds to finish\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
